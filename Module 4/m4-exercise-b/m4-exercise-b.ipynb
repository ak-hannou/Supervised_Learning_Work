{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cCTF923Ksrg"
   },
   "source": [
    "# Module 4: Exercise B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9CpXDAIJF2q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a cleaned-up dataset from an income survey, which includes demographic data. The target variable indicates whether the income exceeds $50K per year, based on census data.\n",
    "\n",
    "Let's import and explore the \"income_cleaned.csv\" file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS1rEsc-JF2v"
   },
   "outputs": [],
   "source": [
    "income = pd.read_csv('income_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 1__\n",
    ">\n",
    ">Generate meta information and the first 5 lines of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check meta information about the features\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 lines\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCzD1x2YSqNy"
   },
   "source": [
    "Let's first visualize these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 2__\n",
    ">\n",
    ">Create a jointplot for each pair of these features:\n",
    ">\n",
    ">- __age__ and __education-num__\n",
    ">- __age__ and __hours-per-week__\n",
    ">- __education-num__ and __hours-per-week__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "AwK-eDwK_oVr",
    "outputId": "9d3e77ae-f0d6-4ecd-b37f-3ba60f2093c7"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 3__\n",
    ">\n",
    "> Convert categorical variables to numerical variables of __workclass__, __occupation__, __race__, and __sex__ columns\n",
    ">\n",
    ">- Add the encoded columns to the original DataFrame (Hint: set `drop_first` parameter)\n",
    ">- Drop these four categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R09iiq-iSZOz"
   },
   "source": [
    ">__Task 4__\n",
    ">\n",
    ">- Assign the __income_50k__ column to `y` and the remaining columns to `X`\n",
    ">- Apply `train_test_split` function with a 80(train):20(test) ratio and set `random_state` to 144\n",
    ">- Make sure your function returns `X_train`, `X_test`, `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R9_RO6mdZ5f"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CHjG7cnjKAe"
   },
   "source": [
    ">__Task 5__\n",
    ">\n",
    "> Train and evaluate a Gaussian NB model\n",
    ">\n",
    ">- Initiate the model\n",
    ">- Fit the model on a train set pair: `X_train` and `y_train`\n",
    ">- Predict on test set `X_test`\n",
    ">- Compare predictions with actual `y_test` values using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2648kbmB4TCe",
    "outputId": "307dba2c-2c3e-4778-8ca1-c1e88fe02a8f"
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Initiate the model\n",
    "...\n",
    "\n",
    "# Fit the model\n",
    "...\n",
    "\n",
    "# Predict\n",
    "...\n",
    "\n",
    "# Calculate the accuracy\n",
    "...\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, __feature scaling__ is a crucial step in the data preprocessing pipeline, particularly for distance-based algorithms like KNN. For instance, if we have two features with scales [0,1] and [1000,2000], the latter feature with larger magnitudes will dominate the distance calculations. Consequently, the feature with the smaller scale will have minimal impact on the distance calculation and, therefore, the KNN predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 6__\n",
    ">\n",
    ">Apply MinMax normalization to the data\n",
    ">\n",
    ">- Initiate a `MinMaxScaler` object with a scale of [0,1]\n",
    ">- Fit on the train set and transform it to `X_train_scaled`\n",
    ">- Transform the test set to `X_test_scaled`\n",
    ">- Check `X_train_scaled`\n",
    ">\n",
    ">__Note:__ You should always fit the scaler to the training set and then apply the scaler to the test set. Performing these operations in the reverse order could result in data leakage, which would bias the performance results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Initiate the scaler\n",
    "...\n",
    "\n",
    "# Fit the scaler to the train set and transform it\n",
    "...\n",
    "\n",
    "# Apply the same scaler to the test set\n",
    "...\n",
    "\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 7__\n",
    ">\n",
    ">Train and evaluate a KNN model\n",
    ">\n",
    ">- Initiate the model with a k value of 15\n",
    ">- Fit the model on a train set pair: `X_train` and `y_train`\n",
    ">- Predict on test set `X_test`\n",
    ">- Compare predictions with actual `y_test` values using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Initiate the model\n",
    "...\n",
    "\n",
    "# Fit the model\n",
    "...\n",
    "\n",
    "# Predict\n",
    "...\n",
    "\n",
    "# Calculate the accuracy\n",
    "...\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 8__\n",
    ">\n",
    "> Repeat the above steps with scaled train set and test set\n",
    ">\n",
    ">- Fit the model on a train set pair: `X_train_scaled` and `y_train`\n",
    ">- Predict on test set `X_test_scaled`\n",
    ">- Compare predictions with actual `y_test` values using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "...\n",
    "\n",
    "# Predict\n",
    "...\n",
    "\n",
    "# Calculate the accuracy\n",
    "...\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks 7 and 8 illustrate the impact of feature scaling on KNN. Interestingly, the accuracy of the KNN model with scaled features is slightly lower. This discrepancy could occur when a large-scale or dominant feature happens to hold high predictive power. \n",
    "\n",
    "Scaling levels the playing field by treating all features equally, which may inadvertently reduce the overall predictive power, especially if a dominant feature played a crucial role in predictions before scaling. Despite this being an uncommon case, it is generally accepted practice to scale the features for KNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 9__\n",
    ">\n",
    ">Use the model from Task 5 to predict the probability of `income_50k` on `X_test` and plot ROC curves of the NB model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "ops6iJ9legss",
    "outputId": "424a0691-571f-4066-fafc-a858f5c00afb"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F9VHIw147pc"
   },
   "source": [
    ">__Task 10__\n",
    ">\n",
    ">Use the model from Task 8 to predict the probability of `income_50k` on `X_test_scaled` and plot ROC curves of the KNN model (with scaled features) predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "aKQh7hHh4zPr",
    "outputId": "edd5d2b9-d245-465b-9058-57243c9c2329"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 11__\n",
    ">\n",
    ">Use `classification_report` to print out _accuracy_, _precision_, _recall_, _accuracy_, and _F1_ scores for both NB and KNN (scaled feature) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH25JXIuhUqU"
   },
   "source": [
    "If you’re not using `classification_report` and are directly calculating each metric instead, you can specify how the average will be calculated for precision, recall, and F1 scores. For example, you could set `average='micro'`. \n",
    "\n",
    "For multiclass or multilabel targets, the `average` parameter is required. If it’s not specified, scores for each class will be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 12__\n",
    ">\n",
    ">Calculate _accuracy_, _precision_, _recall_, and _F1_ scores for the NB model\n",
    ">\n",
    ">- Set `average` to `weighted` for _precision_, _recall_, and _F1_\n",
    ">\n",
    ">Are these metrics the same with the classfication report in Task 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMG6E425fguD",
    "outputId": "1c78438b-2940-4f7b-9192-34f230a02da3"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__Task 13__\n",
    ">\n",
    ">Repeat the above task and calculate _accuracy_, _precision_, _recall_, and _F1_ scores for the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwQOY86m5wL8",
    "outputId": "bf7de543-02c3-49dd-e82f-f3a725f17628"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "3_4_and_5_Exercise_final_Healthcare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
